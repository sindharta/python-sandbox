{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4df3801-545c-4ecb-9acf-8239aa169526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "with open(\"data.json\") as json_data:\n",
    "  data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4346de6-cb8e-43fc-a89c-4cc698ca157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hello', 'Hi', 'I need help', 'Hey'], 'responses': ['Hi there! How can I help?', 'Hello, and welcome to this chatbot'], 'context_set': ''}, {'tag': 'bye', 'patterns': ['Thank you for the help', 'Bye', 'Great thanks'], 'responses': ['Do you have any further questions?', 'Thanks for asking a question']}, {'tag': 'courses', 'patterns': ['What are the courses available?', 'Do you have courses?'], 'responses': ['We have courses on creative design, programming and machine learning', 'We have over 300 courses available']}, {'tag': 'coding', 'patterns': ['What coding courses do you have?', 'I want to learn programming'], 'responses': ['We have many courses, including Hello Coding and Python for Automation', 'Check out our site listing for a complete list of courses']}, {'tag': 'machinelearning', 'patterns': ['What machine learning courses do you teach?', 'Do you teach AI?', 'I want to learn artificial intelligence'], 'responses': ['We have Complete Machine Learning, ChatGPT Bundle and much more', 'Find top machine learning courses in our site catalogue']}, {'tag': 'creative', 'patterns': ['Do you teach creative courses', 'Do you have non coding courses', ' I want to learn something else'], 'responses': ['We have tons of non coding courses', 'Check our site for more courses', ' We teach video editing, audio production, graphic design and much more!']}]}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fcd9457-6d73-46b1-9dd2-8800b2746b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9293950e-455b-476f-b9e5-28f5e186b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "words = []\n",
    "pattern_words_with_tag = []\n",
    "classes = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        pattern_words = nltk.word_tokenize(pattern)\n",
    "\n",
    "        words.extend(pattern_words)\n",
    "        pattern_words_with_tag.append((pattern_words, intent[\"tag\"])) # Tuple type\n",
    "\n",
    "        if intent[\"tag\"] not in classes:\n",
    "            classes.append(intent[\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2617db-7a9a-471a-81f0-5acf83296bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c54fe27-7caa-41e4-9fca-5ca641fe0066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Hi', 'I', 'need', 'help', 'Hey', 'Thank', 'you', 'for', 'the', 'help', 'Bye', 'Great', 'thanks', 'What', 'are', 'the', 'courses', 'available', '?', 'Do', 'you', 'have', 'courses', '?', 'What', 'coding', 'courses', 'do', 'you', 'have', '?', 'I', 'want', 'to', 'learn', 'programming', 'What', 'machine', 'learning', 'courses', 'do', 'you', 'teach', '?', 'Do', 'you', 'teach', 'AI', '?', 'I', 'want', 'to', 'learn', 'artificial', 'intelligence', 'Do', 'you', 'teach', 'creative', 'courses', 'Do', 'you', 'have', 'non', 'coding', 'courses', 'I', 'want', 'to', 'learn', 'something', 'else']\n"
     ]
    }
   ],
   "source": [
    "print(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "513de0a2-52b2-4d02-9dc4-3370d8c5bcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Hello'], 'greeting'), (['Hi'], 'greeting'), (['I', 'need', 'help'], 'greeting'), (['Hey'], 'greeting'), (['Thank', 'you', 'for', 'the', 'help'], 'bye'), (['Bye'], 'bye'), (['Great', 'thanks'], 'bye'), (['What', 'are', 'the', 'courses', 'available', '?'], 'courses'), (['Do', 'you', 'have', 'courses', '?'], 'courses'), (['What', 'coding', 'courses', 'do', 'you', 'have', '?'], 'coding'), (['I', 'want', 'to', 'learn', 'programming'], 'coding'), (['What', 'machine', 'learning', 'courses', 'do', 'you', 'teach', '?'], 'machinelearning'), (['Do', 'you', 'teach', 'AI', '?'], 'machinelearning'), (['I', 'want', 'to', 'learn', 'artificial', 'intelligence'], 'machinelearning'), (['Do', 'you', 'teach', 'creative', 'courses'], 'creative'), (['Do', 'you', 'have', 'non', 'coding', 'courses'], 'creative'), (['I', 'want', 'to', 'learn', 'something', 'else'], 'creative')]\n"
     ]
    }
   ],
   "source": [
    "#a list of tuples\n",
    "print(pattern_words_with_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aacbaaf0-8381-4330-aa98-fdb2ef0ca587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['greeting', 'bye', 'courses', 'coding', 'machinelearning', 'creative']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68a3dbec-8952-4468-84a3-b823e101f13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', 'ai', 'ar', 'art', 'avail', 'bye', 'cod', 'cours', 'cre', 'do', 'els', 'for', 'gre', 'hav', 'hello', 'help', 'hey', 'hi', 'i', 'intellig', 'learn', 'machin', 'nee', 'non', 'program', 'someth', 'teach', 'thank', 'the', 'to', 'want', 'what', 'you']\n"
     ]
    }
   ],
   "source": [
    "#  Clean chat data for machine learning\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "words_lowercase = [stemmer.stem(word.lower()) for word in words]\n",
    "\n",
    "# converting to set will remove duplicate elements\n",
    "unique_words = sorted(list(set(words_lowercase)))\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06f9a36b-d5b5-4470-9a3d-30bfb755cd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Hello'], 'greeting'), (['Hi'], 'greeting'), (['I', 'need', 'help'], 'greeting'), (['Hey'], 'greeting'), (['Thank', 'you', 'for', 'the', 'help'], 'bye'), (['Bye'], 'bye'), (['Great', 'thanks'], 'bye'), (['What', 'are', 'the', 'courses', 'available', '?'], 'courses'), (['Do', 'you', 'have', 'courses', '?'], 'courses'), (['What', 'coding', 'courses', 'do', 'you', 'have', '?'], 'coding'), (['I', 'want', 'to', 'learn', 'programming'], 'coding'), (['What', 'machine', 'learning', 'courses', 'do', 'you', 'teach', '?'], 'machinelearning'), (['Do', 'you', 'teach', 'AI', '?'], 'machinelearning'), (['I', 'want', 'to', 'learn', 'artificial', 'intelligence'], 'machinelearning'), (['Do', 'you', 'teach', 'creative', 'courses'], 'creative'), (['Do', 'you', 'have', 'non', 'coding', 'courses'], 'creative'), (['I', 'want', 'to', 'learn', 'something', 'else'], 'creative')]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "['i', 'want', 'to', 'learn', 'someth', 'els']\n"
     ]
    }
   ],
   "source": [
    "#  Build bag of words for ML model\n",
    "\n",
    "print(documents)\n",
    "\n",
    "empty_output = [0] * len(classes)\n",
    "print(empty_output)\n",
    "training_data = []\n",
    "\n",
    "for tuple in pattern_words_with_tag:\n",
    "    bag_of_words = []\n",
    "\n",
    "    # Tuple: ([pattern_words], tag)\n",
    "    pattern_words = tuple[0]\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "\n",
    "    for unique_word in unique_words:\n",
    "        bag_of_words.append(1) if unique_word in pattern_words else bag_of_words.append(0)\n",
    "\n",
    "    output_row = list(empty_output)\n",
    "    output_row[classes.index(tuple[1])] = 1\n",
    "    training_data.append([bag_of_words, output_row])\n",
    "\n",
    "print(pattern_words)\n",
    "#print(training_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
