{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df3801-545c-4ecb-9acf-8239aa169526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "with open(\"data.json\") as json_data:\n",
    "    data = json.load(json_data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd9457-6d73-46b1-9dd2-8800b2746b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293950e-455b-476f-b9e5-28f5e186b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "pattern_words_with_tag = []\n",
    "classes = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        pattern_words = nltk.word_tokenize(pattern)\n",
    "\n",
    "        words.extend(pattern_words)\n",
    "        pattern_words_with_tag.append((pattern_words, intent[\"tag\"])) # Tuple type\n",
    "\n",
    "        if intent[\"tag\"] not in classes:\n",
    "            classes.append(intent[\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54fe27-7caa-41e4-9fca-5ca641fe0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513de0a2-52b2-4d02-9dc4-3370d8c5bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a list of tuples\n",
    "print(pattern_words_with_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbaaf0-8381-4330-aa98-fdb2ef0ca587",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3dbec-8952-4468-84a3-b823e101f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Clean chat data for machine learning\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "words_lowercase = [stemmer.stem(word.lower()) for word in words]\n",
    "\n",
    "# converting to set will remove duplicate elements\n",
    "unique_words = sorted(list(set(words_lowercase)))\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c803008-bdbd-4d6f-abd3-b687de0589ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_output = [0] * len(classes)\n",
    "print(empty_output)\n",
    "\n",
    "output_row = list(empty_output)\n",
    "print(output_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f9a36b-d5b5-4470-9a3d-30bfb755cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Build bag of words for ML model\n",
    "\n",
    "# print(documents)\n",
    "empty_output = [0] * len(classes)\n",
    "# print(empty_output)\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for tuple in pattern_words_with_tag:\n",
    "    bag_of_words = []\n",
    "\n",
    "    # Tuple: ([pattern_words], tag)\n",
    "    pattern_words = tuple[0]\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "\n",
    "    for unique_word in unique_words:\n",
    "        bag_of_words.append(1) if unique_word in pattern_words else bag_of_words.append(0)\n",
    "\n",
    "    output_row = list(empty_output)\n",
    "    output_row[classes.index(tuple[1])] = 1\n",
    "    training_data.append([bag_of_words, output_row])\n",
    "\n",
    "#print(pattern_words)\n",
    "\n",
    "#training_data: a list of a tuple of ([bag of words], [bag of tag])\n",
    "#https://en.wikipedia.org/wiki/Bag-of-words_model\n",
    "print(training_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09154986-690c-4b06-a709-d478efebd5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f9072-bca1-4cc8-8d87-4fe2cf138e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split data for machine learning\n",
    "\n",
    "import random\n",
    "random.shuffle(training_data)\n",
    "\n",
    "#print(training_data)\n",
    "#print(type(training_data))\n",
    "\n",
    "import numpy\n",
    "training_numpy = numpy.array(training_data, dtype=object)\n",
    "\n",
    "#print(training_numpy)\n",
    "#print(type(training_numpy))\n",
    "\n",
    "train_X = list(training_numpy[:,0]) # to access column 0\n",
    "\n",
    "print(train_X)\n",
    "#print(len(train_X))\n",
    "\n",
    "train_Y = list(training_numpy[:,1]) # to access column 1\n",
    "print(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a41ec-a653-4859-a5dd-4bc299949d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Build a TensorFlow machine learning model for chat\n",
    "\n",
    "import tflearn \n",
    "neural_network = tflearn.input_data(shape = [None, len(train_X[0])])\n",
    "print(neural_network)\n",
    "\n",
    "neural_network = tflearn.fully_connected(neural_network, 8)\n",
    "print(neural_network)\n",
    "\n",
    "neural_network = tflearn.fully_connected(neural_network, 8)\n",
    "print(neural_network)\n",
    "\n",
    "neural_network = tflearn.fully_connected(neural_network, len(train_Y[0]), activation=\"softmax\")\n",
    "print(neural_network)\n",
    "\n",
    "neural_network = tflearn.regression(neural_network)\n",
    "print(neural_network)\n",
    "\n",
    "model = tflearn.DNN(neural_network)\n",
    "print(model)\n",
    "\n",
    "model.fit(train_X, train_Y, n_epoch = 2000, batch_size = 8, show_metric = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef22d1-ea57-4af7-a7e3-fad4fbf4f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test chatbot machine learning model\n",
    "model.save(\"chatbot_dnn.tflearn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad54c91-8f71-49de-82f9-292afae92f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(\"chatbot_dnn.tflearn\")\n",
    "\n",
    "print(model)\n",
    "\n",
    "question = \"Do you sell any coding course?\"\n",
    "\n",
    "def process_question(question):\n",
    "    question_tokenized = nltk.word_tokenize(question)\n",
    "    question_stemmed = [stemmer.stem(word.lower()) for word in question_tokenized]\n",
    "\n",
    "    bag = [0] * len(unique_words)\n",
    "\n",
    "    for stem in question_stemmed:\n",
    "        for index, word in enumerate(unique_words):\n",
    "            if word == stem:\n",
    "                bag[index] = 1\n",
    "\n",
    "    return(numpy.array(bag))\n",
    "\n",
    "processed_question = process_question(question)\n",
    "print(len(processed_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc6394-1e4a-4457-884a-57e7fa29767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([processed_question])\n",
    "print(prediction)\n",
    "#print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77652004-5beb-493a-811a-d5fcbc1a0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(prediction):\n",
    "    prediction_top = [[index, result] for index,result in enumerate(prediction) if result > 0.5]    \n",
    "    prediction_top.sort(key=lambda x: x[1], reverse = True)     \n",
    "    result = []\n",
    "\n",
    "    for prediction_value in prediction_top:\n",
    "        result.append((classes[prediction_value[0]], prediction_value[1]))    \n",
    "    return result\n",
    "\n",
    "prediction_result = categorize(prediction[0])\n",
    "print(prediction_result)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3afeb48-c518-4f82-a304-22c2f642dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(question):\n",
    "    prediction = model.predict([process_question(question)])   \n",
    "    result = categorize(prediction[0])    \n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ba1a54-bb9f-4b73-84aa-0b0847db04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a chatbot response in top category\n",
    "\n",
    "user_input = input(\"Do you have a question for me?\\n\")\n",
    "print(user_input)\n",
    "def respond_to_input(user_input):   \n",
    "    question_category = chatbot(user_input)    \n",
    "    if question_category:\n",
    "        for intent in data[\"intents\"]:\n",
    "            if intent[\"tag\"] == question_category[0][0]:\n",
    "                return random.choice(intent[\"responses\"])\n",
    "    else:\n",
    "        print(\"Could you please clarify your question ?\")\n",
    "        \n",
    "respond_to_input(user_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a0afa-c227-4f7c-84d3-fc4ecb5e43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    user_input = input(\"Do you have a question for me?\\n\")\n",
    "    response = respond_to_input(user_input)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
